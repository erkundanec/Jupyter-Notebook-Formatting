{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all required libraries\n",
    "import os\n",
    "import codecs\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = datasets.MNIST('/Users/kundankumar/Downloads/myDatabase/MNISTpytorch/',train = True, download=True)\n",
    "dataPath = '/Users/kundankumar/Downloads/myDatabase/MNISTpytorch/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseByte(b):\n",
    "    if isinstance(b,str):\n",
    "        return ord(b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInt(b):\n",
    "    return int(codecs.encode(b,'hex'),16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImageFile(path):\n",
    "    with open(path,'rb') as f:\n",
    "        data = f.read()\n",
    "        assert getInt(data[:4])==2051\n",
    "        length =getInt(data[4:8])\n",
    "        nRows = getInt(data[8:12])\n",
    "        nCols = getInt(data[12:16])\n",
    "        images = []\n",
    "        idx = 16\n",
    "        for l in range(length):\n",
    "            img = []\n",
    "            images.append(img)\n",
    "            for r in range(nRows):\n",
    "                row = []\n",
    "                img.append(row)\n",
    "                for c in range(nCols):\n",
    "                    row.append(parseByte(data[idx]))\n",
    "                    idx +=1\n",
    "        assert len(images) == length\n",
    "        return torch.ByteTensor(images).view(-1,784)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = readImageFile(os.path.join(dataPath,'train-images-idx3-ubyte'))\n",
    "testImages = readImageFile(os.path.join(dataPath,'t10k-images-idx3-ubyte'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLabelFile(path):\n",
    "    with open(path,'rb') as f:\n",
    "        data = f.read()\n",
    "        assert getInt(data[:4]) == 2049\n",
    "        length = getInt(data[4:8])\n",
    "        labels = [parseByte(b) for b in data[8:]]\n",
    "        assert len(labels) == length\n",
    "        return torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLabels = readLabelFile(os.path.join(dataPath,'train-labels-idx1-ubyte'))\n",
    "testLabels = readLabelFile(os.path.join(dataPath,'t10k-labels-idx1-ubyte'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# print number of training and testing images\n",
    "print(trainImages.size())\n",
    "print(testImages.size())\n",
    "print(trainLabels.size())\n",
    "print(testLabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgShow(img):\n",
    "    img = img.view(28,28).numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(img,cmap = 'gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1265f3150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1265f30d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgShow(trainImages[2,:])\n",
    "imgShow(testImages[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "# test GPU availability\n",
    "useGPU = torch.cuda.is_available()\n",
    "if useGPU:\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Autoencoder\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28*28,100),nn.ReLU())\n",
    "        self.decoder = nn.Sequential(nn.Linear(100,28*28),nn.ReLU())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=784, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = autoencoder()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useGPU:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store initial weights in a variable\n",
    "import copy\n",
    "initWeights = copy.deepcopy(net.encoder[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Criterion function and Optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr = 0.5,momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Iteration : 1 / 10  ;  Mean-Squared Error : 0.001902\n",
      "At Iteration : 2 / 10  ;  Mean-Squared Error : 0.001891\n",
      "At Iteration : 3 / 10  ;  Mean-Squared Error : 0.001874\n",
      "At Iteration : 4 / 10  ;  Mean-Squared Error : 0.001852\n",
      "At Iteration : 5 / 10  ;  Mean-Squared Error : 0.001827\n",
      "At Iteration : 6 / 10  ;  Mean-Squared Error : 0.001801\n",
      "At Iteration : 7 / 10  ;  Mean-Squared Error : 0.001773\n",
      "At Iteration : 8 / 10  ;  Mean-Squared Error : 0.001745\n",
      "At Iteration : 9 / 10  ;  Mean-Squared Error : 0.001717\n",
      "At Iteration : 10 / 10  ;  Mean-Squared Error : 0.001687\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "iterations = 10\n",
    "batchSize = 1000\n",
    "for epoch in range(iterations):\n",
    "    runningLoss = 0.0\n",
    "    for i in range(trainImages.size()[0]/batchSize):\n",
    "        inputs = torch.index_select(trainImages,0,torch.linspace(i*batchSize,\\\n",
    "                                        (i+1)*batchSize-1,steps = batchSize).long()).double()\n",
    "        \n",
    "    inputs = inputs/255\n",
    "    # wrap them in Variable\n",
    "    if useGPU:\n",
    "        inputs = Variable(inputs).cuda()\n",
    "    else:\n",
    "        inputs = Variable(inputs)\n",
    "                           \n",
    "    optimizer.zero_grad()        \n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs,inputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    runningLoss += loss.data.item()\n",
    "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,\\\n",
    "                                                                        runningLoss/(60000/batchSize)))\n",
    "                           \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
